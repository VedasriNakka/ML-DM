{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divine-department",
   "metadata": {},
   "source": [
    "### Week5: Machine Learning & Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "contrary-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, f_regression, chi2, mutual_info_classif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "statutory-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in original data: 887\n",
      "\n",
      "Features present in dataset: \n",
      " Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
      "       'Parents/Children Aboard', 'Fare'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass                                                Name Sex  \\\n",
      "0         0       3                              Mr. Owen Harris Braund   1   \n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cumings   0   \n",
      "2         1       3                               Miss. Laina Heikkinen   0   \n",
      "3         1       1         Mrs. Jacques Heath (Lily May Peel) Futrelle   0   \n",
      "4         0       3                             Mr. William Henry Allen   1   \n",
      "\n",
      "    Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
      "0  22.0                        1                        0   7.2500  \n",
      "1  38.0                        1                        0  71.2833  \n",
      "2  26.0                        0                        0   7.9250  \n",
      "3  35.0                        1                        0  53.1000  \n",
      "4  35.0                        0                        0   8.0500  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',None)\n",
    "titanic = pd.read_csv('./titanic.csv')\n",
    "print(\"Number of samples in original data: {}\\n\".format(len(titanic.index)))\n",
    "\n",
    "columns = titanic.columns\n",
    "print(\"Features present in dataset: \\n\", columns)\n",
    "\n",
    "titanic.loc[titanic['Sex'] == 'male', 'Sex']=1\n",
    "titanic.loc[titanic['Sex'] == 'female', 'Sex']=0\n",
    "print(titanic.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-association",
   "metadata": {},
   "source": [
    "### Q1. Predict the class ‘Survived’ with a k-nearest neighbours classifier with 3 distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "complete-bradley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: (785, 6)\n",
      "No of test samples: (100, 6)\n",
      "y training samples: (785,)\n",
      "y test samples: (100,)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors = 3, metric = 'manhattan')\n",
    "\n",
    "xd = titanic[[\"Pclass\",\"Sex\",\"Age\",\"Siblings/Spouses Aboard\",\"Parents/Children Aboard\",\"Fare\"]]\n",
    "yd = le.fit(titanic[\"Survived\"])\n",
    "yd = le.transform(titanic[\"Survived\"])\n",
    "\n",
    "xd_train =  xd[:-102]\n",
    "xd_test  =  xd[-102:-2]\n",
    "\n",
    "yd_train =  yd[:-102]\n",
    "yd_test  =  yd[-102:-2]\n",
    "\n",
    "print(\"No of training samples: {}\".format(xd_train.shape))\n",
    "print(\"No of test samples: {}\".format(xd_test.shape))\n",
    "print(\"y training samples: {}\".format(yd_train.shape))\n",
    "print(\"y test samples: {}\".format(yd_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fuzzy-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n",
      "[[51 14]\n",
      " [13 22]]\n"
     ]
    }
   ],
   "source": [
    "knnclassifier.fit(xd_train, yd_train)\n",
    "y_pred_m = knnclassifier.predict(xd_test)\n",
    "acc_manhattan = accuracy_score(yd_test, y_pred_m)\n",
    "print(acc_manhattan)\n",
    "print(confusion_matrix(yd_test,y_pred_m))\n",
    "#print(y_pred_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "needed-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "[[52 13]\n",
      " [12 23]]\n"
     ]
    }
   ],
   "source": [
    "knnclassifier_e = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
    "\n",
    "knnclassifier_e.fit(xd_train, yd_train)\n",
    "y_pred_e = knnclassifier_e.predict(xd_test)\n",
    "\n",
    "acc_euclidien = accuracy_score(yd_test, y_pred_e)\n",
    "print(acc_euclidien)\n",
    "print(confusion_matrix(yd_test,y_pred_e))\n",
    "#print(y_pred_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "suspended-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n",
      "[[56  9]\n",
      " [14 21]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knnclassifier_c = KNeighborsClassifier(n_neighbors = 3, metric = 'cosine')\n",
    "\n",
    "knnclassifier_c.fit(xd_train, yd_train)\n",
    "y_pred_c = knnclassifier_c.predict(xd_test)\n",
    "acc_cosine = accuracy_score(yd_test, y_pred_c)\n",
    "print(acc_cosine)\n",
    "print(confusion_matrix(yd_test,y_pred_c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-correction",
   "metadata": {},
   "source": [
    "### which distance do you think is the best distance measure? and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-consciousness",
   "metadata": {},
   "source": [
    "As above accuracy of manhattan, euclidien, cosine, Cosine is best distance measure because it gives the accuracy of 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-founder",
   "metadata": {},
   "source": [
    "### Q2. determine the number attributes that is capable of giving the best prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "subjective-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original data: 3692\n",
      "Features:  Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adjusted'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./IBM.txt', delimiter = \" \")\n",
    "df_raw = df\n",
    "print(\"Number of rows in original data: {}\".format(len(df.index)))\n",
    "print(\"Features: \", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "mounted-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in processed data: 3692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Daily_returns</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>98.790001</td>\n",
       "      <td>96.879997</td>\n",
       "      <td>98.309998</td>\n",
       "      <td>10524500</td>\n",
       "      <td>63.802544</td>\n",
       "      <td>1.069190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.949997</td>\n",
       "      <td>96.910004</td>\n",
       "      <td>97.419998</td>\n",
       "      <td>7221300</td>\n",
       "      <td>63.224930</td>\n",
       "      <td>-0.905300</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>98.349998</td>\n",
       "      <td>98.900002</td>\n",
       "      <td>10340000</td>\n",
       "      <td>64.185463</td>\n",
       "      <td>1.519199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>99.080002</td>\n",
       "      <td>100.330002</td>\n",
       "      <td>99.070000</td>\n",
       "      <td>100.070000</td>\n",
       "      <td>11108200</td>\n",
       "      <td>64.944771</td>\n",
       "      <td>1.183011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>97.930000</td>\n",
       "      <td>98.889999</td>\n",
       "      <td>8744800</td>\n",
       "      <td>64.178978</td>\n",
       "      <td>-1.179176</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>98.650002</td>\n",
       "      <td>8000700</td>\n",
       "      <td>64.023201</td>\n",
       "      <td>-0.242691</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>98.989998</td>\n",
       "      <td>99.690002</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.339996</td>\n",
       "      <td>6636500</td>\n",
       "      <td>64.471024</td>\n",
       "      <td>0.699436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>99.400002</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>99.300003</td>\n",
       "      <td>100.820000</td>\n",
       "      <td>9602200</td>\n",
       "      <td>65.431503</td>\n",
       "      <td>1.489837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open        High        Low       Close    Volume  \\\n",
       "1  2007-01-04  97.250000   98.790001  96.879997   98.309998  10524500   \n",
       "2  2007-01-05  97.599998   97.949997  96.910004   97.419998   7221300   \n",
       "3  2007-01-08  98.500000   99.500000  98.349998   98.900002  10340000   \n",
       "4  2007-01-09  99.080002  100.330002  99.070000  100.070000  11108200   \n",
       "5  2007-01-10  98.500000   99.050003  97.930000   98.889999   8744800   \n",
       "6  2007-01-11  99.000000   99.900002  98.500000   98.650002   8000700   \n",
       "7  2007-01-12  98.989998   99.690002  98.500000   99.339996   6636500   \n",
       "8  2007-01-16  99.400002  100.839996  99.300003  100.820000   9602200   \n",
       "\n",
       "    Adjusted  Daily_returns  Decision  \n",
       "1  63.802544       1.069190         1  \n",
       "2  63.224930      -0.905300        -1  \n",
       "3  64.185463       1.519199         1  \n",
       "4  64.944771       1.183011         1  \n",
       "5  64.178978      -1.179176        -1  \n",
       "6  64.023201      -0.242691        -1  \n",
       "7  64.471024       0.699436         1  \n",
       "8  65.431503       1.489837         1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['Daily_returns'] = 100*((df['Close'] - df['Close'].shift())/ df['Close'].shift())\n",
    "conditions = [(df['Daily_returns'] >= 0.0),(df['Daily_returns'] < 0.0)]\n",
    "# 1 for UP. -1 for Down\n",
    "values = [1, -1]\n",
    "df['Decision'] = np.select(conditions, values)\n",
    "#df['Decision(next_day)'] = df['Decision'].shift(-1)\n",
    "print(\"Number of rows in processed data: {}\".format(len(df.index)))\n",
    "\n",
    "df_new = df[1:-2]\n",
    "#df_new['Decision(next_day)'] = df_new['Decision(next_day)'].astype('int32')\n",
    "df_new.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "floating-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Open        High        Low       Close    Volume   Adjusted\n",
      "1  97.250000   98.790001  96.879997   98.309998  10524500  63.802544\n",
      "2  97.599998   97.949997  96.910004   97.419998   7221300  63.224930\n",
      "3  98.500000   99.500000  98.349998   98.900002  10340000  64.185463\n",
      "4  99.080002  100.330002  99.070000  100.070000  11108200  64.944771\n",
      "5  98.500000   99.050003  97.930000   98.889999   8744800  64.178978\n",
      "(3689,)\n",
      "No of training samples : (3587, 6)\n",
      "No of test samples     : (100, 6)\n",
      "\n",
      "y training samples : (3587,)\n",
      "y test samples     : (100,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### df_new_IBM = df_new.copy()\n",
    "\n",
    "xd_IBM = df_new_IBM[[ \"Open\", \"High\", \"Low\", \"Close\",\"Volume\", \"Adjusted\"]]\n",
    "print(xd_IBM.head(5))\n",
    "le = preprocessing.LabelEncoder()\n",
    "decision = le.fit(df_new_IBM[\"Decision\"])\n",
    "decision = le.transform(df_new_IBM[\"Decision\"])\n",
    "print(decision.shape)\n",
    "\n",
    "\n",
    "xd_train_knn =  xd_IBM[:-102]\n",
    "xd_test_knn  =  xd_IBM[-102:-2]\n",
    "\n",
    "yd_train_knn =  decision[:-102]\n",
    "yd_test_knn  =  decision[-102:-2]\n",
    "\n",
    "print(\"No of training samples : {}\".format(xd_train_knn.shape))\n",
    "print(\"No of test samples     : {}\\n\".format(xd_test_knn.shape))\n",
    "print(\"y training samples : {}\".format(yd_train_knn.shape))\n",
    "print(\"y test samples     : {}\\n\".format(yd_test_knn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "beautiful-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Accuracy of 1 neighbors is: 0.5\n",
      "confusion_matrix \n",
      " [[ 8 36]\n",
      " [14 42]]\n",
      "------------\n",
      "Accuracy of 3 neighbors is: 0.48\n",
      "confusion_matrix \n",
      " [[ 8 36]\n",
      " [16 40]]\n",
      "------------\n",
      "Accuracy of 5 neighbors is: 0.5\n",
      "confusion_matrix \n",
      " [[11 33]\n",
      " [17 39]]\n",
      "------------\n",
      "Accuracy of 7 neighbors is: 0.5\n",
      "confusion_matrix \n",
      " [[ 7 37]\n",
      " [13 43]]\n",
      "------------\n",
      "Accuracy of 9 neighbors is: 0.52\n",
      "confusion_matrix \n",
      " [[ 9 35]\n",
      " [13 43]]\n",
      "------------\n",
      "Accuracy of 11 neighbors is: 0.51\n",
      "confusion_matrix \n",
      " [[ 6 38]\n",
      " [11 45]]\n",
      "------------\n",
      "Accuracy of 13 neighbors is: 0.46\n",
      "confusion_matrix \n",
      " [[ 5 39]\n",
      " [15 41]]\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,15,2):\n",
    "    knnclassifier_IBM = KNeighborsClassifier(n_neighbors = k, metric = 'cosine')\n",
    "\n",
    "    knnclassifier_IBM.fit(xd_train_knn, yd_train_knn)\n",
    "    y_pred_knn = knnclassifier_IBM.predict(xd_test_knn)\n",
    "    acc_knn = accuracy_score(yd_test_knn, y_pred_knn)\n",
    "    print(\"------------\")\n",
    "    print(\"Accuracy of {} neighbors is: {}\".format(k,acc_knn))\n",
    "    print(\"confusion_matrix \\n\",confusion_matrix(yd_test_knn,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-samba",
   "metadata": {},
   "source": [
    "#### By using *f_classif* feature selection it gives good score for the feature \"Volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "peripheral-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature     Score\n",
      "4    Volume  4.265510\n",
      "0      Open  1.504121\n",
      "5  Adjusted  0.633138\n",
      "3     Close  0.394569\n",
      "1      High  0.133339\n",
      "2       Low  0.063128\n"
     ]
    }
   ],
   "source": [
    "features = SelectKBest(f_classif, k=6).fit(xd_train_knn, yd_train_knn)\n",
    "df_scores = pd.DataFrame(features.scores_)\n",
    "df_cols = pd.DataFrame(xd_train_knn.columns)\n",
    "\n",
    "feature_scores = pd.concat([df_cols, df_scores], axis=1)\n",
    "feature_scores.columns = [\"Feature\", \"Score\"]\n",
    "print(feature_scores.nlargest(6, \"Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "billion-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature     Score\n",
      "4    Volume  4.265510\n",
      "0      Open  1.504121\n",
      "5  Adjusted  0.633138\n",
      "3     Close  0.394569\n",
      "1      High  0.133339\n",
      "2       Low  0.063128\n"
     ]
    }
   ],
   "source": [
    "features = SelectKBest(f_regression, k=6).fit(xd_train_knn, yd_train_knn)\n",
    "df_scores = pd.DataFrame(features.scores_)\n",
    "df_cols = pd.DataFrame(xd_train_knn.columns)\n",
    "\n",
    "feature_scores = pd.concat([df_cols, df_scores], axis=1)\n",
    "feature_scores.columns = [\"Feature\", \"Score\"]\n",
    "print(feature_scores.nlargest(6, \"Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "wicked-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature         Score\n",
      "4    Volume  7.994296e+06\n",
      "0      Open  9.952064e+00\n",
      "5  Adjusted  3.605536e+00\n",
      "3     Close  2.608075e+00\n",
      "1      High  8.737601e-01\n",
      "2       Low  4.220623e-01\n"
     ]
    }
   ],
   "source": [
    "features = SelectKBest(chi2, k=6).fit(xd_train_knn, yd_train_knn)\n",
    "df_scores = pd.DataFrame(features.scores_)\n",
    "df_cols = pd.DataFrame(xd_train_knn.columns)\n",
    "\n",
    "feature_scores = pd.concat([df_cols, df_scores], axis=1)\n",
    "feature_scores.columns = [\"Feature\", \"Score\"]\n",
    "print(feature_scores.nlargest(6, \"Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "pursuant-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature     Score\n",
      "3     Close  0.008422\n",
      "0      Open  0.000000\n",
      "1      High  0.000000\n",
      "2       Low  0.000000\n",
      "4    Volume  0.000000\n",
      "5  Adjusted  0.000000\n"
     ]
    }
   ],
   "source": [
    "features = SelectKBest(mutual_info_classif, k=6).fit(xd_train_knn, yd_train_knn)\n",
    "df_scores = pd.DataFrame(features.scores_)\n",
    "df_cols = pd.DataFrame(xd_train_knn.columns)\n",
    "\n",
    "feature_scores = pd.concat([df_cols, df_scores], axis=1)\n",
    "feature_scores.columns = [\"Feature\", \"Score\"]\n",
    "print(feature_scores.nlargest(6, \"Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
