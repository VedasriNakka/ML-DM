{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greek-processor",
   "metadata": {},
   "source": [
    "## Week 7: Machine Learning & Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-praise",
   "metadata": {},
   "source": [
    "### Q1. Predicting the class ‘Survived’ with Decision tree, KNN, Na¨ıve Bayes classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loving-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in original data: 887\n",
      "Features present in dataset: \n",
      " ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading Titanic data\n",
    "\n",
    "titanic = pd.read_csv('./titanic.csv')\n",
    "print(\"Number of points in original data: {}\".format(len(titanic.index)))\n",
    "\n",
    "columns = titanic.columns\n",
    "print(\"Features present in dataset: \\n\", list(columns))\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-regard",
   "metadata": {},
   "source": [
    "#### Converting continuous attaribute into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appropriate-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(titanic['Age'] < 25.0),(titanic['Age'] > 45.0), \n",
    "              (titanic['Age'] > 25.0) & (titanic['Age'] < 45.0)]\n",
    "\n",
    "values = [1, 3, 2]\n",
    "titanic['New_age'] = np.select(conditions, values)\n",
    "#titanic\n",
    "conditions = [(titanic['Fare'] < 15),(titanic['Fare'] > 50), \n",
    "              (titanic['Fare'] > 15) & (titanic['Fare'] < 50)]\n",
    "\n",
    "values = [1, 3, 2]\n",
    "titanic['New_Fare'] = np.select(conditions, values)\n",
    "\n",
    "#titanic.loc[titanic['Siblings/Spouses Aboard'] == 1 , 'Siblings/Spouses Aboard'] = 'True'\n",
    "#titanic\n",
    "\n",
    "titanic.loc[titanic['Sex'] == 'male', 'Sex'] = 1\n",
    "titanic.loc[titanic['Sex'] == 'female', 'Sex'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-genealogy",
   "metadata": {},
   "source": [
    "#### Removing continuous attributes after creating new attribute of same column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binary-house",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>New_age</th>\n",
       "      <th>New_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name Sex  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   1   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   0   \n",
       "2           1       3                              Miss. Laina Heikkinen   0   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   0   \n",
       "4           0       3                            Mr. William Henry Allen   1   \n",
       "..        ...     ...                                                ...  ..   \n",
       "882         0       2                               Rev. Juozas Montvila   1   \n",
       "883         1       1                        Miss. Margaret Edith Graham   0   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   0   \n",
       "885         1       1                               Mr. Karl Howell Behr   1   \n",
       "886         0       3                                 Mr. Patrick Dooley   1   \n",
       "\n",
       "     Siblings/Spouses Aboard  Parents/Children Aboard  New_age  New_Fare  \n",
       "0                          1                        0        1         1  \n",
       "1                          1                        0        2         3  \n",
       "2                          0                        0        2         1  \n",
       "3                          1                        0        2         3  \n",
       "4                          0                        0        2         1  \n",
       "..                       ...                      ...      ...       ...  \n",
       "882                        0                        0        2         1  \n",
       "883                        0                        0        1         2  \n",
       "884                        1                        2        1         2  \n",
       "885                        0                        0        2         2  \n",
       "886                        0                        0        2         1  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.drop(columns=['Age','Fare'], axis = 1, inplace = True)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: (576, 6)\n",
      "No of test samples    : (311, 6)\n",
      "y training samples    : (576,)\n",
      "y test samples        : (311,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>New_age</th>\n",
       "      <th>New_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass Sex  Siblings/Spouses Aboard  Parents/Children Aboard  New_age  \\\n",
       "243       3   1                        0                        0        2   \n",
       "518       3   1                        0                        0        1   \n",
       "35        1   1                        1                        0        2   \n",
       "81        3   0                        0                        0        2   \n",
       "159       3   1                        0                        1        2   \n",
       "\n",
       "     New_Fare  \n",
       "243         1  \n",
       "518         1  \n",
       "35          3  \n",
       "81          1  \n",
       "159         2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "x = titanic[[\"Pclass\",\"Sex\",\"Siblings/Spouses Aboard\",\"Parents/Children Aboard\", \"New_age\",\"New_Fare\"]]\n",
    "y = le.fit(titanic[\"Survived\"])\n",
    "y = le.transform(titanic[\"Survived\"])\n",
    "\n",
    "\n",
    "# set the random state \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.35, random_state=0)\n",
    "\n",
    "print(\"No of training samples: {}\".format(x_train.shape))\n",
    "print(\"No of test samples    : {}\".format(x_test.shape))\n",
    "print(\"y training samples    : {}\".format(y_train.shape))\n",
    "print(\"y test samples        : {}\".format(y_test.shape))\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-promotion",
   "metadata": {},
   "source": [
    "#### a. Accuracy of the classifies with 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pharmaceutical-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of decision tree of each fold is:\n",
      " [0.7752808988764045, 0.7921348314606742, 0.807909604519774, 0.768361581920904, 0.8248587570621468]\n",
      "Average accuracy of decision tree is 79.37%\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "dt_kfold = KFold(n_splits = k, random_state = None)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_acc_score = []\n",
    "#print(x_train.shape)\n",
    "dt_precision = []\n",
    "dt_recall = []\n",
    "dt_f1 = []\n",
    "\n",
    "for train_index, test_index in dt_kfold.split(x):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    dt_x_train, dt_x_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "    dt_y_train, dt_y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    dt_model.fit(dt_x_train,dt_y_train)\n",
    "    dt_predict = dt_model.predict(dt_x_test)\n",
    "    dt_acc = accuracy_score(dt_predict, dt_y_test)\n",
    "    dt_acc_score.append(dt_acc)\n",
    "    \n",
    "    precision_tree = precision_score(dt_y_test, dt_predict)\n",
    "    dt_precision.append(precision_tree)\n",
    "    \n",
    "    recall_tree = recall_score(dt_y_test, dt_predict)\n",
    "    dt_recall.append(recall_tree)\n",
    "    \n",
    "    f1_tree = f1_score(dt_y_test, dt_predict)\n",
    "    dt_f1.append(f1_tree)\n",
    "\n",
    "avg_dt_acc_score = sum(dt_acc_score)/k\n",
    "print(\"Accuracy of decision tree of each fold is:\\n {}\".format(dt_acc_score))\n",
    "print(\"Average accuracy of decision tree is {:.2f}%\".format(100*avg_dt_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-lancaster",
   "metadata": {},
   "source": [
    "#### Precision, recall, f1 of decion tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sufficient-flashing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of decision tree of each fold is:\n",
      "[0.6727272727272727, 0.8088235294117647, 0.78125, 0.7586206896551724, 0.7758620689655172]\n",
      "precision accuracy of decision tree is:    75.95% \n",
      "\n",
      "Recall of decision tree of each fold is:\n",
      "[0.6271186440677966, 0.6962025316455697, 0.7142857142857143, 0.6197183098591549, 0.7142857142857143]\n",
      "Recall accuracy of decision tree is:       67.43% \n",
      "\n",
      "F1 of decision tree of each fold is:\n",
      "[0.6491228070175439, 0.7482993197278912, 0.7462686567164178, 0.6821705426356589, 0.7438016528925621] \n",
      "F1 accuracy of decision tree is:           71.39% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_dt_precision = sum(dt_precision)/k\n",
    "print(\"Precision of decision tree of each fold is:\\n{}\".format(dt_precision))\n",
    "print(\"precision accuracy of decision tree is:    {:.2f}% \\n\".format(100*avg_dt_precision))\n",
    "\n",
    "avg_dt_recall = sum(dt_recall)/k\n",
    "print(\"Recall of decision tree of each fold is:\\n{}\".format(dt_recall))\n",
    "print(\"Recall accuracy of decision tree is:       {:.2f}% \\n\".format(100*avg_dt_recall))\n",
    "\n",
    "avg_dt_f1 = sum(dt_f1)/k\n",
    "print(\"F1 of decision tree of each fold is:\\n{} \".format(dt_f1))\n",
    "print(\"F1 accuracy of decision tree is:           {:.2f}% \\n\".format(100*avg_dt_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-question",
   "metadata": {},
   "source": [
    "#### Finding accuracy of K-fold, precision, recall and f1-score of KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reserved-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN of each fold is:\n",
      "[0.7528089887640449, 0.7921348314606742, 0.8022598870056498, 0.7966101694915254, 0.8305084745762712]\n",
      "Average accuracy of knn is:       79.49%\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "knn_kfold = KFold(n_splits = k, random_state = None)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_acc_score = []\n",
    "#print(x_train.shape)\n",
    "knn_precision = []\n",
    "knn_recall = []\n",
    "knn_f1 = []\n",
    "\n",
    "for train_index_knn, test_index_knn in knn_kfold.split(x):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    knn_x_train, knn_x_test = x.iloc[train_index_knn,:], x.iloc[test_index_knn,:]\n",
    "    knn_y_train, knn_y_test = y[train_index_knn], y[test_index_knn]\n",
    "    \n",
    "    knn_model.fit(knn_x_train,knn_y_train)\n",
    "    knn_predict = knn_model.predict(knn_x_test)\n",
    "    knn_acc = accuracy_score(knn_predict, knn_y_test)\n",
    "    knn_acc_score.append(knn_acc)\n",
    "    \n",
    "    precision_knn = precision_score(knn_y_test, knn_predict)\n",
    "    knn_precision.append(precision_knn)\n",
    "    \n",
    "    recall_knn = recall_score(knn_y_test, knn_predict)\n",
    "    knn_recall.append(recall_knn)\n",
    "    \n",
    "    f1_knn = f1_score(knn_y_test, knn_predict)\n",
    "    knn_f1.append(f1_knn)\n",
    "\n",
    "avg_knn_acc_score = sum(knn_acc_score)/k\n",
    "print(\"Accuracy of KNN of each fold is:\\n{}\".format(knn_acc_score))\n",
    "print(\"Average accuracy of knn is:       {:.2f}%\".format(100*avg_knn_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "shaped-store",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of KNN of each fold is:\n",
      "[0.6119402985074627, 0.7763157894736842, 0.7536231884057971, 0.8571428571428571, 0.8666666666666667]\n",
      "precision accuracy of KNN is:    77.31% \n",
      "\n",
      "Recall of KNN of each fold is:\n",
      "[0.6949152542372882, 0.7468354430379747, 0.7428571428571429, 0.5915492957746479, 0.6190476190476191]\n",
      "Recall accuracy of KNN is:       67.90% \n",
      "\n",
      "F1 of KNN of each fold is:\n",
      "[0.6507936507936508, 0.7612903225806452, 0.748201438848921, 0.7000000000000001, 0.7222222222222222] \n",
      "F1 accuracy of KNN is:           71.65% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_knn_precision = sum(knn_precision)/k\n",
    "print(\"Precision of KNN of each fold is:\\n{}\".format(knn_precision))\n",
    "print(\"precision accuracy of KNN is:    {:.2f}% \\n\".format(100*avg_knn_precision))\n",
    "\n",
    "avg_knn_recall = sum(knn_recall)/k\n",
    "print(\"Recall of KNN of each fold is:\\n{}\".format(knn_recall))\n",
    "print(\"Recall accuracy of KNN is:       {:.2f}% \\n\".format(100*avg_knn_recall))\n",
    "\n",
    "avg_knn_f1 = sum(knn_f1)/k\n",
    "print(\"F1 of KNN of each fold is:\\n{} \".format(knn_f1))\n",
    "print(\"F1 accuracy of KNN is:           {:.2f}% \\n\".format(100*avg_knn_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-cardiff",
   "metadata": {},
   "source": [
    "#### After calculated KNN classifier by direct devide the data into training and test got accuracy 79.10% and by deviding the training data into 5 folds got an average accuracy of 79.49% I observed that both accuracies are almost same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "utility-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy   : 79.10%\n",
      "KNN precision  : 75.00%\n",
      "KNN Accuracy   : 69.42%\n",
      "KNN Accuracy   : 72.10%\n",
      "KNN confusion_matrix :\n",
      "[[162  28]\n",
      " [ 37  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       190\n",
      "           1       0.75      0.69      0.72       121\n",
      "\n",
      "    accuracy                           0.79       311\n",
      "   macro avg       0.78      0.77      0.78       311\n",
      "weighted avg       0.79      0.79      0.79       311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knnclassifier = KNeighborsClassifier(n_neighbors = 3, metric = 'cosine')\n",
    "knnclassifier.fit(x_train.values, y_train)\n",
    "knn_y_pred = knnclassifier.predict(x_test.values)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, knn_y_pred)\n",
    "print(\"KNN Accuracy   : {:.2f}%\".format(100*knn_acc))\n",
    "\n",
    "knn_precision = precision_score(y_test, knn_y_pred)\n",
    "print(\"KNN precision  : {:.2f}%\".format(100*knn_precision))\n",
    "\n",
    "knn_recall = recall_score(y_test, knn_y_pred)\n",
    "print(\"KNN Accuracy   : {:.2f}%\".format(100*knn_recall))\n",
    "\n",
    "knn_f1 = f1_score(y_test, knn_y_pred)\n",
    "print(\"KNN Accuracy   : {:.2f}%\".format(100*knn_f1))\n",
    "\n",
    "print(\"KNN confusion_matrix :\\n{}\".format(confusion_matrix(y_test,knn_y_pred)))\n",
    "\n",
    "KNN_report = classification_report(y_test, knn_y_pred)\n",
    "print(KNN_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-franklin",
   "metadata": {},
   "source": [
    "#### Finding accuracy of K-fold, precision, recall and f1-score of Naive bays classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dietary-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian of each fold is:\n",
      "[0.7134831460674157, 0.7640449438202247, 0.7740112994350282, 0.7796610169491526, 0.807909604519774]\n",
      "Average accuracy of Gaussian is:       76.78%\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "g_kfold = KFold(n_splits = k, random_state = None)\n",
    "g_model = GaussianNB()\n",
    "g_acc_score = []\n",
    "#print(x_train.shape)\n",
    "g_precision = []\n",
    "g_recall = []\n",
    "g_f1 = []\n",
    "\n",
    "for train_index_g, test_index_g in g_kfold.split(x):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    g_x_train, g_x_test = x.iloc[train_index_g,:], x.iloc[test_index_g,:]\n",
    "    g_y_train, g_y_test = y[train_index_g], y[test_index_g]\n",
    "    \n",
    "    g_model.fit(g_x_train,g_y_train)\n",
    "    g_predict = g_model.predict(g_x_test)\n",
    "    g_acc = accuracy_score(g_predict, g_y_test)\n",
    "    g_acc_score.append(g_acc)\n",
    "    \n",
    "    precision_g = precision_score(g_y_test, g_predict)\n",
    "    g_precision.append(precision_g)\n",
    "    \n",
    "    recall_g = recall_score(g_y_test, g_predict)\n",
    "    g_recall.append(recall_g)\n",
    "    \n",
    "    f1_g = f1_score(g_y_test, g_predict)\n",
    "    g_f1.append(f1_g)\n",
    "\n",
    "avg_g_acc_score = sum(g_acc_score)/k\n",
    "print(\"Accuracy of Gaussian of each fold is:\\n{}\".format(g_acc_score))\n",
    "print(\"Average accuracy of Gaussian is:       {:.2f}%\".format(100*avg_g_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "buried-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Gaussian of each fold is:\n",
      "[0.5487804878048781, 0.7176470588235294, 0.6666666666666666, 0.7424242424242424, 0.7230769230769231]\n",
      "precision accuracy of Gaussian is:    67.97% \n",
      "\n",
      "Recall of Gaussian of each fold is:\n",
      "[0.7627118644067796, 0.7721518987341772, 0.8571428571428571, 0.6901408450704225, 0.746031746031746]\n",
      "Recall accuracy of Gaussian is:       76.56% \n",
      "\n",
      "F1 of Gaussian of each fold is:\n",
      "[0.6382978723404256, 0.7439024390243902, 0.75, 0.7153284671532847, 0.7343749999999999] \n",
      "F1 accuracy of Gaussian is:           71.64% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_g_precision = sum(g_precision)/k\n",
    "print(\"Precision of Gaussian of each fold is:\\n{}\".format(g_precision))\n",
    "print(\"precision accuracy of Gaussian is:    {:.2f}% \\n\".format(100*avg_g_precision))\n",
    "\n",
    "avg_g_recall = sum(g_recall)/k\n",
    "print(\"Recall of Gaussian of each fold is:\\n{}\".format(g_recall))\n",
    "print(\"Recall accuracy of Gaussian is:       {:.2f}% \\n\".format(100*avg_g_recall))\n",
    "\n",
    "avg_g_f1 = sum(g_f1)/k\n",
    "print(\"F1 of Gaussian of each fold is:\\n{} \".format(g_f1))\n",
    "print(\"F1 accuracy of Gaussian is:           {:.2f}% \\n\".format(100*avg_g_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-optics",
   "metadata": {},
   "source": [
    "### Q2. Building Decision tree, KNN, Naıve Bayes models with selected stock using all attributes to predict ‘daily returns’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-somewhere",
   "metadata": {},
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diagnostic-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original data: 3692\n",
      "Features:  ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adjusted']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./IBM.txt', delimiter = \" \")\n",
    "df_raw = df\n",
    "print(\"Number of rows in original data: {}\".format(len(df.index)))\n",
    "print(\"Features: \", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adaptive-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in processed data: 3692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Daily_returns</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Decision(next_day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>98.790001</td>\n",
       "      <td>96.879997</td>\n",
       "      <td>98.309998</td>\n",
       "      <td>10524500</td>\n",
       "      <td>63.802544</td>\n",
       "      <td>1.069190</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.949997</td>\n",
       "      <td>96.910004</td>\n",
       "      <td>97.419998</td>\n",
       "      <td>7221300</td>\n",
       "      <td>63.224930</td>\n",
       "      <td>-0.905300</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>98.349998</td>\n",
       "      <td>98.900002</td>\n",
       "      <td>10340000</td>\n",
       "      <td>64.185463</td>\n",
       "      <td>1.519199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>99.080002</td>\n",
       "      <td>100.330002</td>\n",
       "      <td>99.070000</td>\n",
       "      <td>100.070000</td>\n",
       "      <td>11108200</td>\n",
       "      <td>64.944771</td>\n",
       "      <td>1.183011</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>97.930000</td>\n",
       "      <td>98.889999</td>\n",
       "      <td>8744800</td>\n",
       "      <td>64.178978</td>\n",
       "      <td>-1.179176</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>98.650002</td>\n",
       "      <td>8000700</td>\n",
       "      <td>64.023201</td>\n",
       "      <td>-0.242691</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>98.989998</td>\n",
       "      <td>99.690002</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.339996</td>\n",
       "      <td>6636500</td>\n",
       "      <td>64.471024</td>\n",
       "      <td>0.699436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>99.400002</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>99.300003</td>\n",
       "      <td>100.820000</td>\n",
       "      <td>9602200</td>\n",
       "      <td>65.431503</td>\n",
       "      <td>1.489837</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open        High        Low       Close    Volume  \\\n",
       "1  2007-01-04  97.250000   98.790001  96.879997   98.309998  10524500   \n",
       "2  2007-01-05  97.599998   97.949997  96.910004   97.419998   7221300   \n",
       "3  2007-01-08  98.500000   99.500000  98.349998   98.900002  10340000   \n",
       "4  2007-01-09  99.080002  100.330002  99.070000  100.070000  11108200   \n",
       "5  2007-01-10  98.500000   99.050003  97.930000   98.889999   8744800   \n",
       "6  2007-01-11  99.000000   99.900002  98.500000   98.650002   8000700   \n",
       "7  2007-01-12  98.989998   99.690002  98.500000   99.339996   6636500   \n",
       "8  2007-01-16  99.400002  100.839996  99.300003  100.820000   9602200   \n",
       "\n",
       "    Adjusted  Daily_returns  Decision  Decision(next_day)  \n",
       "1  63.802544       1.069190         1                  -1  \n",
       "2  63.224930      -0.905300        -1                   1  \n",
       "3  64.185463       1.519199         1                   1  \n",
       "4  64.944771       1.183011         1                  -1  \n",
       "5  64.178978      -1.179176        -1                  -1  \n",
       "6  64.023201      -0.242691        -1                   1  \n",
       "7  64.471024       0.699436         1                   1  \n",
       "8  65.431503       1.489837         1                  -1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "df['Daily_returns'] = 100*((df['Close'] - df['Close'].shift())/ df['Close'].shift())\n",
    "conditions = [(df['Daily_returns'] >= 0.0),(df['Daily_returns'] < 0.0)]\n",
    "# 1 for UP. -1 for Down\n",
    "\n",
    "values1 = [1, -1]\n",
    "df['Decision'] = np.select(conditions, values1)\n",
    "df['Decision(next_day)'] = df['Decision'].shift(-1)\n",
    "print(\"Number of rows in processed data: {}\".format(len(df.index)))\n",
    "\n",
    "df_new = df[1:-2]\n",
    "df_new['Decision(next_day)'] = df_new['Decision(next_day)'].astype('int32')\n",
    "df_new.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "awful-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Daily_returns</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Decision(next_day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.069190</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.905300</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.519199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.183011</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.179176</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.366612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.157571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100</td>\n",
       "      <td>150.0</td>\n",
       "      <td>-0.772202</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.453960</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3689 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Open   High    Low  Close  Volume  Adjusted  Daily_returns  \\\n",
       "1     2007-01-04  100.0  100.0  100.0  100.0     150     100.0       1.069190   \n",
       "2     2007-01-05  100.0  100.0  100.0  100.0     120     100.0      -0.905300   \n",
       "3     2007-01-08  100.0  100.0  100.0  100.0     150     100.0       1.519199   \n",
       "4     2007-01-09  100.0  120.0  100.0  120.0     150     100.0       1.183011   \n",
       "5     2007-01-10  100.0  100.0  100.0  100.0     120     100.0      -1.179176   \n",
       "...          ...    ...    ...    ...    ...     ...       ...            ...   \n",
       "3685  2021-08-23  150.0  150.0  150.0  150.0     100     150.0       0.366612   \n",
       "3686  2021-08-24  150.0  150.0  150.0  150.0     100     150.0       0.157571   \n",
       "3687  2021-08-25  150.0  150.0  150.0  150.0     100     150.0       0.014306   \n",
       "3688  2021-08-26  150.0  150.0  150.0  150.0     100     150.0      -0.772202   \n",
       "3689  2021-08-27  150.0  150.0  150.0  150.0     100     150.0       0.453960   \n",
       "\n",
       "      Decision  Decision(next_day)  \n",
       "1            1                  -1  \n",
       "2           -1                   1  \n",
       "3            1                   1  \n",
       "4            1                  -1  \n",
       "5           -1                  -1  \n",
       "...        ...                 ...  \n",
       "3685         1                   1  \n",
       "3686         1                   1  \n",
       "3687         1                  -1  \n",
       "3688        -1                   1  \n",
       "3689         1                  -1  \n",
       "\n",
       "[3689 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "df_new.loc[df_new['Open'] < 100, 'Open'] = 100\n",
    "df_new.loc[(df_new['Open'] > 100)&(df_new['Open'] < 120), 'Open'] = 120\n",
    "df_new.loc[df_new['Open'] > 120, 'Open'] = 150\n",
    "\n",
    "df_new.loc[df_new['High'] < 100, 'High'] = 100\n",
    "df_new.loc[((df_new['High'] > 100)&(df_new['High'] < 120)), 'High'] = 120\n",
    "df_new.loc[df_new['High'] > 120, 'High'] = 150\n",
    "\n",
    "df_new.loc[df_new['Low'] < 100, 'Low'] = 100\n",
    "df_new.loc[((df_new['Low'] > 100)&(df_new['Low'] < 120)), 'Low'] = 120\n",
    "df_new.loc[df_new['Low'] > 120, 'Low'] = 150\n",
    "\n",
    "df_new.loc[df_new['Adjusted'] < 100, 'Adjusted'] = 100\n",
    "df_new.loc[((df_new['Adjusted'] > 100)&(df_new['Adjusted'] < 120)), 'Adjusted'] = 120\n",
    "df_new.loc[df_new['Adjusted'] > 120, 'Adjusted'] = 150\n",
    "\n",
    "df_new.loc[df_new['Close'] < 100, 'Close'] = 100\n",
    "df_new.loc[((df_new['Close'] > 100)&(df_new['Close'] < 120)), 'Close'] = 120\n",
    "df_new.loc[df_new['Close'] > 120, 'Close'] = 150\n",
    "\n",
    "df_new.loc[df_new['Volume'] <= 3039600, 'Volume'] = 100\n",
    "df_new.loc[((df_new['Volume'] > 3039600)&(df_new['Volume'] < 10000000)), 'Volume'] = 120\n",
    "df_new.loc[df_new['Volume'] > 10000000, 'Volume'] = 150\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-superintendent",
   "metadata": {},
   "source": [
    "#### Split the data. Last 100 rows as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "forbidden-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples : (3587, 6)\n",
      "No of test samples     : (100, 6)\n",
      "\n",
      "y training samples     : (3587,)\n",
      "y test samples         : (100,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_IBM = df_new.copy()\n",
    "xd_IBM = df_new_IBM[[ \"Open\", \"High\", \"Low\", \"Close\",\"Volume\", \"Adjusted\"]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "decision = le.fit(df_new_IBM[\"Decision(next_day)\"])\n",
    "decision = le.transform(df_new_IBM[\"Decision(next_day)\"])\n",
    "\n",
    "xd_train_dt =  xd_IBM[:-102]\n",
    "xd_test_dt  =  xd_IBM[-102:-2]\n",
    "\n",
    "yd_train_dt =  decision[:-102]\n",
    "yd_test_dt  =  decision[-102:-2]\n",
    "\n",
    "print(\"No of training samples : {}\".format(xd_train_dt.shape))\n",
    "print(\"No of test samples     : {}\\n\".format(xd_test_dt.shape))\n",
    "print(\"y training samples     : {}\".format(yd_train_dt.shape))\n",
    "print(\"y test samples         : {}\\n\".format(yd_test_dt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "organized-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of IBM decision tree of each fold is:\n",
      " [0.5176151761517616, 0.46070460704607047, 0.46883468834688347, 0.5176151761517616, 0.46612466124661245, 0.48509485094850946, 0.5338753387533876, 0.5230352303523035, 0.5176151761517616, 0.5434782608695652]\n",
      "Average accuracy of IBM decision tree is:        50.34%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "k = 10\n",
    "dt_kfold_ibm = KFold(n_splits = k, random_state = None)\n",
    "dt_model_ibm = DecisionTreeClassifier()\n",
    "dt_acc_score_ibm = []\n",
    "#print(x_train.shape)\n",
    "dt_precision_ibm = []\n",
    "dt_recall_ibm = []\n",
    "dt_f1_ibm = []\n",
    "\n",
    "for train_index_ibm, test_index_ibm in dt_kfold_ibm.split(xd_IBM):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    dt_x_train_ibm, dt_x_test_ibm = xd_IBM.iloc[train_index_ibm,:], xd_IBM.iloc[test_index_ibm,:]\n",
    "    dt_y_train_ibm, dt_y_test_ibm = decision[train_index_ibm], decision[test_index_ibm]\n",
    "    \n",
    "    dt_model_ibm.fit(dt_x_train_ibm, dt_y_train_ibm)\n",
    "    dt_predict_ibm = dt_model_ibm.predict(dt_x_test_ibm)\n",
    "    dt_acc_ibm = accuracy_score(dt_predict_ibm, dt_y_test_ibm)\n",
    "    dt_acc_score_ibm.append(dt_acc_ibm)\n",
    "    \n",
    "    precision_tree_ibm = precision_score(dt_y_test_ibm, dt_predict_ibm)\n",
    "    #print(precision_tree_ibm)\n",
    "    dt_precision_ibm.append(precision_tree_ibm)\n",
    "    \n",
    "    recall_tree_ibm = recall_score(dt_y_test_ibm, dt_predict_ibm)\n",
    "    dt_recall_ibm.append(recall_tree_ibm)\n",
    "    \n",
    "    f1_tree_ibm = f1_score(dt_y_test_ibm, dt_predict_ibm)\n",
    "    dt_f1_ibm.append(f1_tree_ibm)\n",
    "\n",
    "avg_dt_acc_score_ibm = sum(dt_acc_score_ibm)/k\n",
    "print(\"Accuracy of IBM decision tree of each fold is:\\n {}\".format(dt_acc_score_ibm))\n",
    "print(\"Average accuracy of IBM decision tree is:        {:.2f}%\".format(100*avg_dt_acc_score_ibm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "still-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of IBM decision tree of each fold is:\n",
      "[0.5363984674329502, 0.45493562231759654, 0.5202702702702703, 0.5625, 0.3620689655172414, 0.4835164835164835, 0.5486381322957199, 0.5681818181818182, 0.546875, 0.5679611650485437]\n",
      "precision accuracy of IBM decision tree is:    51.51% \n",
      "\n",
      "Recall of IBM decision tree of each fold is:\n",
      "[0.7106598984771574, 0.5955056179775281, 0.3811881188118812, 0.28421052631578947, 0.11602209944751381, 0.9887640449438202, 0.7157360406091371, 0.26595744680851063, 0.5357142857142857, 0.5969387755102041]\n",
      "Recall accuracy of IBM decision tree is:       51.91% \n",
      "\n",
      "F1 of IBM decision tree of each fold is:\n",
      "[0.611353711790393, 0.5158150851581509, 0.44, 0.3776223776223776, 0.17573221757322177, 0.6494464944649446, 0.6211453744493393, 0.36231884057971014, 0.5412371134020619, 0.5820895522388059] \n",
      "F1 accuracy of IBM decision tree is:           48.77% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_dt_precision_ibm = sum(dt_precision_ibm)/k\n",
    "print(\"Precision of IBM decision tree of each fold is:\\n{}\".format(dt_precision_ibm))\n",
    "print(\"precision accuracy of IBM decision tree is:    {:.2f}% \\n\".format(100*avg_dt_precision_ibm))\n",
    "\n",
    "avg_dt_recall_ibm = sum(dt_recall_ibm)/k\n",
    "print(\"Recall of IBM decision tree of each fold is:\\n{}\".format(dt_recall_ibm))\n",
    "print(\"Recall accuracy of IBM decision tree is:       {:.2f}% \\n\".format(100*avg_dt_recall_ibm))\n",
    "\n",
    "avg_dt_f1_ibm = sum(dt_f1_ibm)/k\n",
    "print(\"F1 of IBM decision tree of each fold is:\\n{} \".format(dt_f1_ibm))\n",
    "print(\"F1 accuracy of IBM decision tree is:           {:.2f}% \\n\".format(100*avg_dt_f1_ibm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-fault",
   "metadata": {},
   "source": [
    "#### Finding accuracy of K-fold, precision, recall and f1-score of KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "specific-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of IBM KNN of each fold is:\n",
      " [0.5203252032520326, 0.4634146341463415, 0.46883468834688347, 0.5176151761517616, 0.5094850948509485, 0.5338753387533876, 0.5013550135501355, 0.5040650406504065, 0.4905149051490515, 0.5543478260869565]\n",
      "Average accuracy of IBM KNN is:        50.64%\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "knn_kfold_ibm = KFold(n_splits = k, random_state = None)\n",
    "knn_model_ibm = KNeighborsClassifier()\n",
    "knn_acc_score_ibm = []\n",
    "#print(x_train.shape)\n",
    "knn_precision_ibm = []\n",
    "knn_recall_ibm = []\n",
    "knn_f1_ibm = []\n",
    "\n",
    "for train_index_ibm, test_index_ibm in knn_kfold_ibm.split(xd_IBM):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    knn_x_train_ibm, knn_x_test_ibm = xd_IBM.iloc[train_index_ibm,:], xd_IBM.iloc[test_index_ibm,:]\n",
    "    knn_y_train_ibm, knn_y_test_ibm = decision[train_index_ibm], decision[test_index_ibm]\n",
    "    \n",
    "    knn_model_ibm.fit(knn_x_train_ibm, knn_y_train_ibm)\n",
    "    knn_predict_ibm = knn_model_ibm.predict(knn_x_test_ibm)\n",
    "    knn_acc_ibm = accuracy_score(knn_predict_ibm, knn_y_test_ibm)\n",
    "    knn_acc_score_ibm.append(knn_acc_ibm)\n",
    "    \n",
    "    precision_tree_ibm_knn = precision_score(knn_y_test_ibm, knn_predict_ibm)\n",
    "    #print(precision_tree_ibm)\n",
    "    knn_precision_ibm.append(precision_tree_ibm_knn)\n",
    "    \n",
    "    recall_tree_ibm_knn = recall_score(knn_y_test_ibm, knn_predict_ibm)\n",
    "    knn_recall_ibm.append(recall_tree_ibm_knn)\n",
    "    \n",
    "    f1_tree_ibm_knn = f1_score(knn_y_test_ibm, knn_predict_ibm)\n",
    "    knn_f1_ibm.append(f1_tree_ibm_knn)\n",
    "\n",
    "avg_knn_acc_score_ibm = sum(knn_acc_score_ibm)/k\n",
    "print(\"Accuracy of IBM KNN of each fold is:\\n {}\".format(knn_acc_score_ibm))\n",
    "print(\"Average accuracy of IBM KNN is:        {:.2f}%\".format(100*avg_knn_acc_score_ibm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "empty-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of IBM KNN of each fold is:\n",
      "[0.5485436893203883, 0.4618320610687023, 0.52, 0.5625, 0.0, 0.5340909090909091, 0.5414012738853503, 0.5581395348837209, 0.5487804878048781, 0.5747663551401869]\n",
      "precision accuracy of IBM KNN is:    48.50% \n",
      "\n",
      "Recall of IBM KNN of each fold is:\n",
      "[0.5736040609137056, 0.6797752808988764, 0.38613861386138615, 0.28421052631578947, 0.0, 0.2640449438202247, 0.43147208121827413, 0.1276595744680851, 0.22959183673469388, 0.6275510204081632]\n",
      "Recall accuracy of IBM KNN is:       36.04% \n",
      "\n",
      "F1 of IBM KNN of each fold is:\n",
      "[0.5607940446650124, 0.55, 0.4431818181818182, 0.3776223776223776, 0.0, 0.3533834586466165, 0.480225988700565, 0.20779220779220778, 0.3237410071942446, 0.6000000000000001] \n",
      "F1 accuracy of IBM KNN is:           38.97% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_knn_precision_ibm = sum(knn_precision_ibm)/k\n",
    "print(\"Precision of IBM KNN of each fold is:\\n{}\".format(knn_precision_ibm))\n",
    "print(\"precision accuracy of IBM KNN is:    {:.2f}% \\n\".format(100*avg_knn_precision_ibm))\n",
    "\n",
    "avg_knn_recall_ibm = sum(knn_recall_ibm)/k\n",
    "print(\"Recall of IBM KNN of each fold is:\\n{}\".format(knn_recall_ibm))\n",
    "print(\"Recall accuracy of IBM KNN is:       {:.2f}% \\n\".format(100*avg_knn_recall_ibm))\n",
    "\n",
    "avg_knn_f1_ibm = sum(knn_f1_ibm)/k\n",
    "print(\"F1 of IBM KNN of each fold is:\\n{} \".format(knn_f1_ibm))\n",
    "print(\"F1 accuracy of IBM KNN is:           {:.2f}% \\n\".format(100*avg_knn_f1_ibm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-toolbox",
   "metadata": {},
   "source": [
    "#### Finding accuracy of K-fold, precision, recall and f1-score of Naive bays classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "crude-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of IBM Gaussian classifier of each fold is:\n",
      " [0.5257452574525745, 0.4823848238482385, 0.5447154471544715, 0.5176151761517616, 0.46612466124661245, 0.48509485094850946, 0.4905149051490515, 0.5040650406504065, 0.5149051490514905, 0.5271739130434783]\n",
      "Average accuracy of IBM Gaussian classifier is:        50.58%\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "g_kfold_ibm = KFold(n_splits = k, random_state = None)\n",
    "g_model_ibm = GaussianNB()\n",
    "g_acc_score_ibm = []\n",
    "#print(x_train.shape)\n",
    "g_precision_ibm = []\n",
    "g_recall_ibm = []\n",
    "g_f1_ibm = []\n",
    "\n",
    "for train_index_ibm, test_index_ibm in g_kfold_ibm.split(xd_IBM):\n",
    "    #print(train_index.shape, test_index.shape)\n",
    "    g_x_train_ibm, g_x_test_ibm = xd_IBM.iloc[train_index_ibm,:], xd_IBM.iloc[test_index_ibm,:]\n",
    "    g_y_train_ibm, g_y_test_ibm = decision[train_index_ibm], decision[test_index_ibm]\n",
    "    \n",
    "    g_model_ibm.fit(g_x_train_ibm, g_y_train_ibm)\n",
    "    g_predict_ibm = g_model_ibm.predict(g_x_test_ibm)\n",
    "    g_acc_ibm = accuracy_score(g_predict_ibm, g_y_test_ibm)\n",
    "    g_acc_score_ibm.append(g_acc_ibm)\n",
    "    \n",
    "    precision_tree_ibmg = precision_score(g_y_test_ibm, g_predict_ibm)\n",
    "    #print(precision_tree_ibm)\n",
    "    g_precision_ibm.append(precision_tree_ibmg)\n",
    "    \n",
    "    recall_tree_ibm_g = recall_score(g_y_test_ibm, g_predict_ibm)\n",
    "    g_recall_ibm.append(recall_tree_ibm_g)\n",
    "    \n",
    "    f1_tree_ibm_g = f1_score(g_y_test_ibm, g_predict_ibm)\n",
    "    g_f1_ibm.append(f1_tree_ibm_g)\n",
    "\n",
    "avg_g_acc_score_ibm = sum(g_acc_score_ibm)/k\n",
    "print(\"Accuracy of IBM Gaussian classifier of each fold is:\\n {}\".format(g_acc_score_ibm))\n",
    "print(\"Average accuracy of IBM Gaussian classifier is:        {:.2f}%\".format(100*avg_g_acc_score_ibm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attractive-terminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of IBM Gaussian classifier of each fold is:\n",
      "[0.5381944444444444, 0.481994459833795, 0.5494186046511628, 0.5625, 0.3620689655172414, 0.48342541436464087, 0.5294117647058824, 0.5581395348837209, 0.5858585858585859, 0.53125]\n",
      "precision accuracy of IBM Gaussian classifier is:    51.82% \n",
      "\n",
      "Recall of IBM Gaussian classifier of each fold is:\n",
      "[0.7868020304568528, 0.9775280898876404, 0.9356435643564357, 0.28421052631578947, 0.11602209944751381, 0.9831460674157303, 0.41116751269035534, 0.1276595744680851, 0.29591836734693877, 0.9540816326530612]\n",
      "Recall accuracy of IBM Gaussian classifier is:       58.72% \n",
      "\n",
      "F1 of IBM Gaussian classifier of each fold is:\n",
      "[0.6391752577319587, 0.6456400742115027, 0.6923076923076924, 0.3776223776223776, 0.17573221757322177, 0.6481481481481481, 0.4628571428571429, 0.20779220779220778, 0.39322033898305087, 0.6824817518248175] \n",
      "F1 accuracy of IBM Gaussian classifier is:           49.25% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_g_precision_ibm = sum(g_precision_ibm)/k\n",
    "print(\"Precision of IBM Gaussian classifier of each fold is:\\n{}\".format(g_precision_ibm))\n",
    "print(\"precision accuracy of IBM Gaussian classifier is:    {:.2f}% \\n\".format(100*avg_g_precision_ibm))\n",
    "\n",
    "avg_g_recall_ibm = sum(g_recall_ibm)/k\n",
    "print(\"Recall of IBM Gaussian classifier of each fold is:\\n{}\".format(g_recall_ibm))\n",
    "print(\"Recall accuracy of IBM Gaussian classifier is:       {:.2f}% \\n\".format(100*avg_g_recall_ibm))\n",
    "\n",
    "avg_g_f1_ibm = sum(g_f1_ibm)/k\n",
    "print(\"F1 of IBM Gaussian classifier of each fold is:\\n{} \".format(g_f1_ibm))\n",
    "print(\"F1 accuracy of IBM Gaussian classifier is:           {:.2f}% \\n\".format(100*avg_g_f1_ibm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-unemployment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
